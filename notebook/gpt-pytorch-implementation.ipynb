{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset\n[truongpdd/vietnamese_poetry](https://huggingface.co/datasets/truongpdd/vietnamese_poetry)","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('truongpdd/vietnamese_poetry')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-11T11:08:54.772301Z","iopub.execute_input":"2024-03-11T11:08:54.772824Z","iopub.status.idle":"2024-03-11T11:09:01.145561Z","shell.execute_reply.started":"2024-03-11T11:08:54.772792Z","shell.execute_reply":"2024-03-11T11:09:01.144739Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/717 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e4591a058ab4f2c8b13148a47f9af6c"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset csv/default (download: 61.91 MiB, generated: 106.76 MiB, post-processed: Unknown size, total: 168.67 MiB) to /root/.cache/huggingface/datasets/parquet/truongpdd--vietnamese_poetry-a78eb18695f6197f/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53014e44f8574b5686b9ac96ff7c8e3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/64.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d34100ce23458f877f3a61f75f6ca2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4caef905374e4dd08ac2468882e59db2"}},"metadata":{}},{"name":"stdout","text":"Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/truongpdd--vietnamese_poetry-a78eb18695f6197f/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701f70d803af4827a06300a1dbe01f9b"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:01.147433Z","iopub.execute_input":"2024-03-11T11:09:01.147882Z","iopub.status.idle":"2024-03-11T11:09:01.154387Z","shell.execute_reply.started":"2024-03-11T11:09:01.147857Z","shell.execute_reply":"2024-03-11T11:09:01.153420Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'the_loai'],\n        num_rows: 171188\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset['train'][0]['text'])\n# print('\\n'.join(dataset['train'][:2]['text']))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:01.155450Z","iopub.execute_input":"2024-03-11T11:09:01.155714Z","iopub.status.idle":"2024-03-11T11:09:01.167401Z","shell.execute_reply.started":"2024-03-11T11:09:01.155672Z","shell.execute_reply":"2024-03-11T11:09:01.166409Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"thơ lục bát: \n ai ơi xa bến quê hương\nnhớ về quê mẹ nắng sương đây nè\nnhớ sao những buổi trưa hè\nvõng đưa cót két gió hè hiu hiu\nlời ru của mẹ dấu yêu\nngọt ngào êm dịu mẹ yêu con nhiều\nlời mẹ năm tháng sớm chiều\ncon nghe nhớ mãi những điều ru ta\nlòng mẹ ôi thật bao la\nthái bình rộng lớn thương là mênh mông\nmột đời lưng mẹ đã còng\nvai mang tay xách lo chồng chăm con\nmong sao con lớn nên người\nthân mẹ có cực vẫn cười thương con\nvì đời mẹ sống cho con\ngom bao mệt nhọc mãi còn vòng tay\nmong chờ cho đến một ngày\ncông thành danh toại là ngày mẹ mong\ndù nay mẹ đã xa rồi\ncon đây nhớ mãi mẹ ôi vạn lần\nnguyện rằng ghi nhớ công ân\nsinh thành dưỡng dục mẫu thân đời đời\n","output_type":"stream"}]},{"cell_type":"code","source":"text = '\\n'.join(dataset['train'][:]['text'])\nlen(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:01.168590Z","iopub.execute_input":"2024-03-11T11:09:01.168958Z","iopub.status.idle":"2024-03-11T11:09:02.517471Z","shell.execute_reply.started":"2024-03-11T11:09:01.168926Z","shell.execute_reply":"2024-03-11T11:09:02.516520Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"83454368"},"metadata":{}}]},{"cell_type":"code","source":"print(text[:100])","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:02.520481Z","iopub.execute_input":"2024-03-11T11:09:02.520812Z","iopub.status.idle":"2024-03-11T11:09:02.525341Z","shell.execute_reply.started":"2024-03-11T11:09:02.520788Z","shell.execute_reply":"2024-03-11T11:09:02.524475Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"thơ lục bát: \n ai ơi xa bến quê hương\nnhớ về quê mẹ nắng sương đây nè\nnhớ sao những buổi trưa hè\nvõn\n","output_type":"stream"}]},{"cell_type":"code","source":"chars = sorted(list(set(text)))\nvocab_size = len(chars)\nprint('chars:',chars)\nprint('vocab_size:', vocab_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:02.526658Z","iopub.execute_input":"2024-03-11T11:09:02.527292Z","iopub.status.idle":"2024-03-11T11:09:04.382263Z","shell.execute_reply.started":"2024-03-11T11:09:02.527260Z","shell.execute_reply":"2024-03-11T11:09:04.381232Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"chars: ['\\x08', '\\n', ' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '¡', '¢', '¤', '¥', '¬', '\\xad', '°', '²', '³', '´', 'µ', '¸', '¹', 'à', 'á', 'â', 'ã', 'ä', 'å', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ÿ', 'ā', 'ă', 'ą', 'ć', 'đ', 'ē', 'ę', 'ě', 'ĩ', 'ī', 'ń', 'ō', 'œ', 'š', 'ť', 'ũ', 'ū', 'ů', 'ơ', 'ƣ', 'ư', 'ǎ', 'ǒ', 'ǚ', 'ǵ', 'ǹ', '̀', '́', '̂', '̃', '̉', '̣', 'γ', 'с', 'ц', 'ḥ', 'ḷ', 'ḿ', 'ṃ', 'ṇ', 'ṕ', 'ṭ', 'ạ', 'ả', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ẹ', 'ẻ', 'ẽ', 'ế', 'ề', 'ể', 'ễ', 'ệ', 'ỉ', 'ị', 'ọ', 'ỏ', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'ụ', 'ủ', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'ỳ', 'ỵ', 'ỷ', 'ỹ', '\\u200b', '\\u200c', '\\u200d', '\\u200e', '₫', '◇', '❄', '❣', '❤', '。', '️', '\\ufeff', '，', '￼', '🍁', '🍂', '💋', '😉', '😔', '😥', '😧', '🤣']\nvocab_size: 194\n","output_type":"stream"}]},{"cell_type":"code","source":"str2int = {char:i for i, char in enumerate(chars)}\nint2str = {i:char for i, char in enumerate(chars)}\nencode = lambda s: [str2int[c] for c in s]\ndecode = lambda lst: ''.join([int2str[i] for i in lst])\nprint(encode('nguyễn gia bình'))\nprint(decode(encode('nguyễn gia bình')))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:04.383491Z","iopub.execute_input":"2024-03-11T11:09:04.383827Z","iopub.status.idle":"2024-03-11T11:09:04.393633Z","shell.execute_reply.started":"2024-03-11T11:09:04.383800Z","shell.execute_reply":"2024-03-11T11:09:04.392578Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[29, 22, 36, 40, 145, 29, 2, 22, 24, 16, 2, 17, 68, 29, 23]\nnguyễn gia bình\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\ndata = torch.tensor(encode(text), dtype=torch.long)\ndata.shape, data.dtype, data[:100]","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:04.394834Z","iopub.execute_input":"2024-03-11T11:09:04.395655Z","iopub.status.idle":"2024-03-11T11:09:26.312108Z","shell.execute_reply.started":"2024-03-11T11:09:04.395617Z","shell.execute_reply":"2024-03-11T11:09:26.311032Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(torch.Size([83454368]),\n torch.int64,\n tensor([ 35,  23, 103,   2,  27, 161,  18,   2,  17,  58,  35,  13,   2,   1,\n           2,  16,  24,   2, 103,  24,   2,  39,  16,   2,  17, 142,  29,   2,\n          32,  36,  66,   2,  23, 105, 103,  29,  22,   1,  29,  23, 156,   2,\n          37, 143,   2,  32,  36,  66,   2,  28, 139,   2,  29, 134,  29,  22,\n           2,  34, 105, 103,  29,  22,   2,  89,  59,  40,   2,  29,  64,   1,\n          29,  23, 156,   2,  34,  16,  30,   2,  29,  23, 166,  29,  22,   2,\n          17,  36, 153,  24,   2,  35,  33, 105,  16,   2,  23,  64,   1,  37,\n          76,  29]))"},"metadata":{}}]},{"cell_type":"code","source":"n = int(0.9*len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:26.313347Z","iopub.execute_input":"2024-03-11T11:09:26.314688Z","iopub.status.idle":"2024-03-11T11:09:26.319519Z","shell.execute_reply.started":"2024-03-11T11:09:26.314651Z","shell.execute_reply":"2024-03-11T11:09:26.318643Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"block_size = 8\nx_train = train_data[:block_size]\ny_train = train_data[1:block_size+1]\nfor i in range(block_size):\n    print(f'context: {x_train[:i+1]} => target: {y_train[i]}')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:09:26.321292Z","iopub.execute_input":"2024-03-11T11:09:26.321696Z","iopub.status.idle":"2024-03-11T11:09:26.342902Z","shell.execute_reply.started":"2024-03-11T11:09:26.321666Z","shell.execute_reply":"2024-03-11T11:09:26.341932Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"context: tensor([35]) => target: 23\ncontext: tensor([35, 23]) => target: 103\ncontext: tensor([ 35,  23, 103]) => target: 2\ncontext: tensor([ 35,  23, 103,   2]) => target: 27\ncontext: tensor([ 35,  23, 103,   2,  27]) => target: 161\ncontext: tensor([ 35,  23, 103,   2,  27, 161]) => target: 18\ncontext: tensor([ 35,  23, 103,   2,  27, 161,  18]) => target: 2\ncontext: tensor([ 35,  23, 103,   2,  27, 161,  18,   2]) => target: 17\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.manual_seed(42)\nbatch_size = 32\nblock_size = 8\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndef get_batch(split):\n    data = train_data if split=='train' else val_data\n    start_idx = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in start_idx])\n    y = torch.stack([data[i+block_size:i+block_size+1] for i in start_idx])\n    x = x.to(device)\n    y = y.to(device)\n    return x, y\n\n# xb, yb = get_batch('train')\n# print('inputs:')\n# print(xb.shape)\n# print(xb)\n# print('targets:')\n# print(yb.shape)\n# print(yb)","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:53:27.663640Z","iopub.execute_input":"2024-03-11T11:53:27.664055Z","iopub.status.idle":"2024-03-11T11:53:27.672826Z","shell.execute_reply.started":"2024-03-11T11:53:27.664026Z","shell.execute_reply":"2024-03-11T11:53:27.671636Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"batch_size = 4\nblock_size = 32\nix = torch.randint(len(data) - block_size, (batch_size,))\nix","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:53:28.142357Z","iopub.execute_input":"2024-03-11T11:53:28.143231Z","iopub.status.idle":"2024-03-11T11:53:28.150093Z","shell.execute_reply.started":"2024-03-11T11:53:28.143197Z","shell.execute_reply":"2024-03-11T11:53:28.149195Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"tensor([23005158, 82952627, 77478748, 36757390])"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\ntorch.manual_seed(42)\nB, T, C = 32, 8, 32 # batch, time, channel\nx = torch.rand(B, T, C)\nhead_size = 16\nkey = nn.Linear(C, head_size, bias=False)\nquery = nn.Linear(C, head_size, bias=False)\nvalue = nn.Linear(C, head_size, bias=False)\nk = key(x)\nq = query(x)\nW = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\ntril = torch.tril(torch.ones(T, T))\nW = W.masked_fill(tril==0, float('-inf'))\nW = F.softmax(W, dim=-1)\nv = value(x) # (B, T, 16)\nout = W @ v # (B, T, T) @ (B, T, 16) > (B, T, 16)\nW[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-11T11:53:28.449910Z","iopub.execute_input":"2024-03-11T11:53:28.450559Z","iopub.status.idle":"2024-03-11T11:53:28.464874Z","shell.execute_reply.started":"2024-03-11T11:53:28.450526Z","shell.execute_reply":"2024-03-11T11:53:28.463975Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.4513, 0.5487, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2947, 0.2783, 0.4270, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2191, 0.2147, 0.3137, 0.2525, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1967, 0.1663, 0.2031, 0.2164, 0.2174, 0.0000, 0.0000, 0.0000],\n        [0.1449, 0.1583, 0.1539, 0.1774, 0.1584, 0.2071, 0.0000, 0.0000],\n        [0.1366, 0.1427, 0.1384, 0.1606, 0.1536, 0.1445, 0.1236, 0.0000],\n        [0.1170, 0.1169, 0.0999, 0.1216, 0.1214, 0.1216, 0.1333, 0.1683]],\n       grad_fn=<SelectBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"class Head(nn.Module):\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        B, T, C  = x.shape\n        k = self.key(x)\n        q = self.query(x)\n        wei = q @ k.transpose(-2, -1)/(C**0.5) #  (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1)\n        wei = self.dropout(wei)\n        v = self.value(x)\n        output = wei @ v # (B, T, T) @ (B, T ,C) > (B, T, C)\n        return output\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embd, n_embd)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = torch.cat([h(x) for h in self.heads], dim=-1)\n        x = self.proj(x)\n        x = self.dropout(x)\n        return x\n\nclass FeedForward(nn.Module):\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4*n_embd),\n            nn.ReLU(),\n            nn.Linear(4*n_embd, n_embd),\n            nn.Dropout(dropout)\n        )\n    def forward(self, x):\n        return self.net(x)\n    \n\nclass DecoderBlock(nn.Module):\n    def __init__(self, n_embd, n_heads):\n        super().__init__()\n        head_size = n_embd//n_heads\n        self.sa = MultiHeadAttention(n_heads, head_size)\n        self.ff = FeedForward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n    \n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ff(self.ln2(x))\n        return x\n\nclass GPT(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[DecoderBlock(n_embd, n_heads=n_heads) for _ in range(n_layers)])\n        self.ln = nn.LayerNorm(n_embd)\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n    \n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n        token_embd = self.token_embedding(idx)\n        position_embd = self.position_embedding(torch.arange(T, device=device))\n        x = token_embd + position_embd\n        x = self.blocks(x)\n        x = self.ln(x)\n        logits = self.lm_head(x)\n        \n        if targets is not None:\n            B, T, C = logits.shape\n#             print(logits.shape, targets.shape)\n            logits = logits.view(B*T, C)\n            \n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n        else:\n            loss = None\n        return logits, loss\n    \n    def generate(self, idx, max_new_tokens):\n        for _ in range(max_new_tokens):\n            idx_cond = idx[:, -block_size:]\n            logits, loss = self(idx_cond)\n            logits = logits[:, -1, :]\n            probs = F.softmax(logits, dim=-1)\n            next_idx = torch.multinomial(probs, num_samples=1)\n            idx = torch.cat((idx, next_idx), dim=1)\n        return idx","metadata":{"execution":{"iopub.status.busy":"2024-03-11T12:31:07.419205Z","iopub.execute_input":"2024-03-11T12:31:07.420317Z","iopub.status.idle":"2024-03-11T12:31:07.442095Z","shell.execute_reply.started":"2024-03-11T12:31:07.420281Z","shell.execute_reply":"2024-03-11T12:31:07.441180Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters).to(device)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-03-11T12:31:07.443600Z","iopub.execute_input":"2024-03-11T12:31:07.444134Z","iopub.status.idle":"2024-03-11T12:31:07.458830Z","shell.execute_reply.started":"2024-03-11T12:31:07.444109Z","shell.execute_reply":"2024-03-11T12:31:07.457960Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"import os\nfrom torch.optim import lr_scheduler\n\nbatch_size = 128 \nblock_size = 32 \nmax_iters = 20000\neval_interval = 100\nlearning_rate = 1e-3\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 64\nn_heads = 4\nn_layers = 4\ndropout = 0.0\nbest_loss = 100000\n\nmodel = GPT()\nmodel = model.to(device)\nif 'last_GPT.pt' in os.listdir('.'):\n    model.load_state_dict(torch.load('last_GPT.pt', map_location=torch.device('cpu')))\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.3)\nprint('model has', sum(p.numel() for p in model.parameters())/1e6, 'M parameters')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:10:05.229582Z","iopub.execute_input":"2024-03-11T13:10:05.229936Z","iopub.status.idle":"2024-03-11T13:10:05.270066Z","shell.execute_reply.started":"2024-03-11T13:10:05.229910Z","shell.execute_reply":"2024-03-11T13:10:05.269116Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"model has 0.22637 M parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_batch(split):\n    data = train_data if split=='train' else val_data\n    start_idx = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in start_idx])\n    y = torch.stack([data[i+1:i+block_size+1] for i in start_idx])\n    x = x.to(device)\n    y = y.to(device)\n    return x, y\nx, y =get_batch('train')\ny.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:10:05.690061Z","iopub.execute_input":"2024-03-11T13:10:05.690909Z","iopub.status.idle":"2024-03-11T13:10:05.706018Z","shell.execute_reply.started":"2024-03-11T13:10:05.690876Z","shell.execute_reply":"2024-03-11T13:10:05.704974Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 32])"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nfor i in range(max_iters):\n    if i % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        if losses['val'] < best_loss:\n            best_loss = losses['val']\n            torch.save(model.state_dict(), 'best_GPT.pt')   \n        print(f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n        \n    xb, yb = get_batch('train')\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n    torch.save(model.state_dict(), 'last_GPT.pt') \n    scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:10:06.199288Z","iopub.execute_input":"2024-03-11T13:10:06.199629Z","iopub.status.idle":"2024-03-11T13:22:12.242476Z","shell.execute_reply.started":"2024-03-11T13:10:06.199603Z","shell.execute_reply":"2024-03-11T13:22:12.240895Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"step 0: train loss 1.5937, val loss 1.6580\nstep 100: train loss 1.6105, val loss 1.6752\nstep 200: train loss 1.6057, val loss 1.6663\nstep 300: train loss 1.6077, val loss 1.6586\nstep 400: train loss 1.6055, val loss 1.6702\nstep 500: train loss 1.6038, val loss 1.6653\nstep 600: train loss 1.6011, val loss 1.6686\nstep 700: train loss 1.6036, val loss 1.6626\nstep 800: train loss 1.6021, val loss 1.6545\nstep 900: train loss 1.6001, val loss 1.6618\nstep 1000: train loss 1.5952, val loss 1.6576\nstep 1100: train loss 1.5826, val loss 1.6493\nstep 1200: train loss 1.5824, val loss 1.6490\nstep 1300: train loss 1.5795, val loss 1.6464\nstep 1400: train loss 1.5809, val loss 1.6423\nstep 1500: train loss 1.5782, val loss 1.6465\nstep 1600: train loss 1.5768, val loss 1.6495\nstep 1700: train loss 1.5770, val loss 1.6425\nstep 1800: train loss 1.5780, val loss 1.6437\nstep 1900: train loss 1.5772, val loss 1.6486\nstep 2000: train loss 1.5746, val loss 1.6447\nstep 2100: train loss 1.5718, val loss 1.6434\nstep 2200: train loss 1.5713, val loss 1.6389\nstep 2300: train loss 1.5706, val loss 1.6431\nstep 2400: train loss 1.5722, val loss 1.6392\nstep 2500: train loss 1.5661, val loss 1.6362\nstep 2600: train loss 1.5697, val loss 1.6379\nstep 2700: train loss 1.5688, val loss 1.6353\nstep 2800: train loss 1.5652, val loss 1.6356\nstep 2900: train loss 1.5715, val loss 1.6380\nstep 3000: train loss 1.5683, val loss 1.6363\nstep 3100: train loss 1.5684, val loss 1.6367\nstep 3200: train loss 1.5651, val loss 1.6358\nstep 3300: train loss 1.5692, val loss 1.6349\nstep 3400: train loss 1.5653, val loss 1.6362\nstep 3500: train loss 1.5669, val loss 1.6421\nstep 3600: train loss 1.5671, val loss 1.6359\nstep 3700: train loss 1.5645, val loss 1.6353\nstep 3800: train loss 1.5642, val loss 1.6375\nstep 3900: train loss 1.5675, val loss 1.6352\nstep 4000: train loss 1.5661, val loss 1.6343\nstep 4100: train loss 1.5666, val loss 1.6385\nstep 4200: train loss 1.5675, val loss 1.6340\nstep 4300: train loss 1.5665, val loss 1.6375\nstep 4400: train loss 1.5671, val loss 1.6345\nstep 4500: train loss 1.5664, val loss 1.6346\nstep 4600: train loss 1.5644, val loss 1.6343\nstep 4700: train loss 1.5650, val loss 1.6374\nstep 4800: train loss 1.5630, val loss 1.6346\nstep 4900: train loss 1.5648, val loss 1.6386\nstep 5000: train loss 1.5635, val loss 1.6344\nstep 5100: train loss 1.5622, val loss 1.6340\nstep 5200: train loss 1.5650, val loss 1.6383\nstep 5300: train loss 1.5642, val loss 1.6347\nstep 5400: train loss 1.5627, val loss 1.6345\nstep 5500: train loss 1.5661, val loss 1.6316\nstep 5600: train loss 1.5606, val loss 1.6332\nstep 5700: train loss 1.5650, val loss 1.6335\nstep 5800: train loss 1.5618, val loss 1.6321\nstep 5900: train loss 1.5655, val loss 1.6377\nstep 6000: train loss 1.5620, val loss 1.6363\nstep 6100: train loss 1.5655, val loss 1.6310\nstep 6200: train loss 1.5671, val loss 1.6350\nstep 6300: train loss 1.5617, val loss 1.6386\nstep 6400: train loss 1.5639, val loss 1.6365\nstep 6500: train loss 1.5628, val loss 1.6369\nstep 6600: train loss 1.5650, val loss 1.6346\nstep 6700: train loss 1.5653, val loss 1.6349\nstep 6800: train loss 1.5626, val loss 1.6335\nstep 6900: train loss 1.5645, val loss 1.6355\nstep 7000: train loss 1.5668, val loss 1.6359\nstep 7100: train loss 1.5652, val loss 1.6347\nstep 7200: train loss 1.5642, val loss 1.6365\nstep 7300: train loss 1.5632, val loss 1.6366\nstep 7400: train loss 1.5639, val loss 1.6353\nstep 7500: train loss 1.5666, val loss 1.6400\nstep 7600: train loss 1.5638, val loss 1.6360\nstep 7700: train loss 1.5676, val loss 1.6332\nstep 7800: train loss 1.5655, val loss 1.6342\nstep 7900: train loss 1.5625, val loss 1.6364\nstep 8000: train loss 1.5642, val loss 1.6352\nstep 8100: train loss 1.5647, val loss 1.6341\nstep 8200: train loss 1.5658, val loss 1.6367\nstep 8300: train loss 1.5641, val loss 1.6339\nstep 8400: train loss 1.5606, val loss 1.6338\nstep 8500: train loss 1.5655, val loss 1.6300\nstep 8600: train loss 1.5635, val loss 1.6385\nstep 8700: train loss 1.5670, val loss 1.6355\nstep 8800: train loss 1.5640, val loss 1.6344\nstep 8900: train loss 1.5633, val loss 1.6328\nstep 9000: train loss 1.5628, val loss 1.6336\nstep 9100: train loss 1.5624, val loss 1.6351\nstep 9200: train loss 1.5641, val loss 1.6352\nstep 9300: train loss 1.5643, val loss 1.6338\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[123], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m==\u001b[39m max_iters \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m         losses \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[1;32m      6\u001b[0m             best_loss \u001b[38;5;241m=\u001b[39m losses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[94], line 9\u001b[0m, in \u001b[0;36mestimate_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[1;32m      8\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m get_batch(split)\n\u001b[0;32m----> 9\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     losses[k] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     11\u001b[0m out[split] \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mmean()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[93], line 76\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m     74\u001b[0m position_embd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding(torch\u001b[38;5;241m.\u001b[39marange(T, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m     75\u001b[0m x \u001b[38;5;241m=\u001b[39m token_embd \u001b[38;5;241m+\u001b[39m position_embd\n\u001b[0;32m---> 76\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m     78\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[93], line 58\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 58\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(x))\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[93], line 30\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([h(x) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n","Cell \u001b[0;32mIn[93], line 30\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[93], line 13\u001b[0m, in \u001b[0;36mHead.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m B, T, C  \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     12\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x)\n\u001b[0;32m---> 13\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m wei \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m(C\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;66;03m#  (B, T, C) @ (B, C, T) -> (B, T, T)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m wei \u001b[38;5;241m=\u001b[39m wei\u001b[38;5;241m.\u001b[39mmasked_fill(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtril[:T, :T] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"context = torch.zeros((1, 1), dtype=torch.long, device=device)\ntext = 'nhớ em'\ncontext = torch.asarray([encode(text)], dtype=torch.long, device=device)\nprint( context)\nprint((decode(con) for con in context))\nprint(decode(model.generate(context, max_new_tokens=200)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T13:34:46.059769Z","iopub.execute_input":"2024-03-11T13:34:46.060130Z","iopub.status.idle":"2024-03-11T13:34:47.577368Z","shell.execute_reply.started":"2024-03-11T13:34:46.060103Z","shell.execute_reply":"2024-03-11T13:34:47.576416Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"tensor([[ 29,  23, 156,   2,  20,  28]], device='cuda:0')\n<generator object <genexpr> at 0x7d66b8c88c10>\nnhớ em còn mây\ngiấu dẫu chắc cũng soi nhòa đất nước\ntrẻ quê chùa đêm đen sông quá hồng\nngó ngào quên dánh vũng nấc vời\nngày xưa về ầm chúm ngọt ngã\nđể lòng ngắm trong hồn nhung ươm con\nta trở đò trọn phố ph\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'GPT.pt')","metadata":{"execution":{"iopub.status.busy":"2024-03-11T12:41:32.644449Z","iopub.execute_input":"2024-03-11T12:41:32.644839Z","iopub.status.idle":"2024-03-11T12:41:32.664909Z","shell.execute_reply.started":"2024-03-11T12:41:32.644808Z","shell.execute_reply":"2024-03-11T12:41:32.663946Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"load_model = GPT().to(device)\nload_model.load_state_dict(torch.load('GPT.pt', map_location=torch.device('cpu')))\nlaod_model.eval()\nprint(decode(load_model.generate(context, max_new_tokens=200)[0].tolist()))","metadata":{"execution":{"iopub.status.busy":"2024-03-11T12:43:09.290796Z","iopub.execute_input":"2024-03-11T12:43:09.291154Z","iopub.status.idle":"2024-03-11T12:43:10.818136Z","shell.execute_reply.started":"2024-03-11T12:43:09.291128Z","shell.execute_reply":"2024-03-11T12:43:10.817158Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"\b ải đã xa\n\nbên sự anh mắt từng lờ biềc với xuân từng sa\nnhìn thơ xanh với mình mây\ntròn nơi lượn cái lòng chưa vời\ncái gươ ngoài tháng mang nụ cười\nsầu bình trời mỹ đêm quận thương\ngiữ lòng soi thẩn b\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}